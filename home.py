import streamlit as st
import os

from langchain_openai import OpenAI, OpenAIEmbeddings
from models.llm import CHATLLM
from workflows.sql_workflow import SQLWorkflow
from utils.data_utils import load_csv_to_sqlite
from configs.examples import EXAMPLES
from langchain.callbacks.base import BaseCallbackHandler
from langchain.vectorstores import FAISS
from langchain_core.tracers import LangChainTracer
from langchain.callbacks.manager import CallbackManager


# OpenAI API í‚¤ ë¡œë“œ
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]

# Langsmith tracingì„ ìœ„í•œ í‚¤ ë¡œë“œ
LANGCHAIN_API_KEY = st.secrets["LANGCHAIN_API_KEY"]
LANGCHAIN_PROJECT = st.secrets["LANGCHAIN_PROJECT"]
LANGCHAIN_TRACING_V2 = "true"
LANGCHAIN_ENDPOINT = "https://api.smith.langchain.com"

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="TourGuideRAG", page_icon="ğŸ¡")

# ë©”ì‹œì§€ ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []


class ChatCallbackHandler(BaseCallbackHandler):
    """
    LLMì´ í† í° ë‹¨ìœ„ë¡œ ì¶œë ¥í•  ë•Œë§ˆë‹¤ Streamlit UIì— ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸í•´ì£¼ëŠ” ì½œë°± í•¸ë“¤ëŸ¬ì…ë‹ˆë‹¤.
    """

    message = ""

    def on_llm_start(self, *args, **kwargs):
        """LLMì´ ì‹œì‘ë  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤. í† í° ëˆ„ì ìš© ë¹ˆ ì»¨í…Œì´ë„ˆë¥¼ ë§Œë“­ë‹ˆë‹¤."""
        self.message_box = st.empty()

    def on_llm_end(self, *args, **kwargs):
        """LLMì´ ì¢…ë£Œë  ë•Œ í˜¸ì¶œë©ë‹ˆë‹¤. ìµœì¢… ë©”ì‹œì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
        save_message(self.message, "ai")

    def on_llm_new_token(self, token, *args, **kwargs):
        """LLMì´ ìƒˆ í† í°ì„ ìƒì„±í•  ë•Œë§ˆë‹¤ í˜¸ì¶œë©ë‹ˆë‹¤. í† í°ì„ ëˆ„ì í•´ UIì— í‘œì‹œí•©ë‹ˆë‹¤."""
        self.message += token
        self.message_box.markdown(self.message)


def save_message(message: str, role: str) -> None:
    """ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤."""
    st.session_state["messages"].append({"message": message, "role": role})


def send_message(message: str, role: str, save: bool = True) -> None:
    """
    ì±„íŒ… UIì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    save=Trueì¸ ê²½ìš°, ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì—ë„ ë©”ì‹œì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
    """
    with st.chat_message(role):
        st.markdown(message)
    if save:
        save_message(message, role)


def paint_history() -> None:
    """ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— ê¸°ë¡ëœ ë©”ì‹œì§€ë¥¼ ëª¨ë‘ ë‹¤ì‹œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    for msg in st.session_state["messages"]:
        send_message(msg["message"], msg["role"], save=False)


@st.cache_resource
def get_sqlite_connection(csv_files):
    return load_csv_to_sqlite(csv_files)


@st.cache_resource
def get_embeddings(api_key):
    return OpenAIEmbeddings(openai_api_key=api_key)


@st.cache_resource
def get_vectorstore_examples(examples, OPENAI_API_KEY):
    questions = [item["question"] for item in examples]
    embeddings = get_embeddings(OPENAI_API_KEY)
    question_embeddings = [
        (question, embeddings.embed_query(question)) for question in questions
    ]
    vectorstore = FAISS.from_embeddings(
        text_embeddings=question_embeddings, embedding=embeddings, metadatas=examples
    )
    return vectorstore


tracer = LangChainTracer(project_name=LANGCHAIN_PROJECT)
callback_manager = CallbackManager([tracer])

csv_files = {
    "./data/pet_places.csv": "pet_places",
}

# LLM ì¸ìŠ¤í„´ìŠ¤ ì¤€ë¹„
llm_stream = OpenAI(
    streaming=True,
    callbacks=[ChatCallbackHandler()],
    openai_api_key=OPENAI_API_KEY,
)

conn = get_sqlite_connection(csv_files)

questions = [item["question"] for item in EXAMPLES]
vectorstore_examples = get_vectorstore_examples(EXAMPLES, OPENAI_API_KEY)

tour_rag = SQLWorkflow(CHATLLM, llm_stream, conn, vectorstore_examples)
app = tour_rag.setup_workflow()

# UI êµ¬ì„±
st.title("ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì‹œì„¤ ê°€ì´ë“œ")
st.write(
    "ğŸŒŸë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì‹œì„¤  ê°€ì´ë“œ ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ê¶ê¸ˆí•˜ì‹  ì •ë³´ë¥¼ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
)
st.write(
    "ğŸŒŸì˜ˆì‹œ ì§ˆë¬¸: ì¢…ë¡œêµ¬ ë¬´ì•…ë™ì— ìˆëŠ” 24ì‹œê°„ ë™ë¬¼ë³‘ì›ì„ ì•Œë ¤ì£¼ì„¸ìš”. ë¶€ì‚° ë™êµ¬ì— ìˆëŠ” ì£¼ì°¨ ê°€ëŠ¥í•œ ì¹´í˜ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. ì¸ì²œì— ìˆëŠ” ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì¶”ê°€ìš”ê¸ˆ ì—†ëŠ” íœì…˜ ì•Œë ¤ì£¼ì„¸ìš”."
)

paint_history()

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
message = st.chat_input("Ask anything about pet facilities...")

if message:
    send_message(message, "human")
    inputs = {"question": message}
    with st.chat_message("ai"):
        response = app.invoke(inputs)

button = st.sidebar.button("Show Workflow")
if button:
    with st.sidebar:
        st.image(app.get_graph().draw_mermaid_png(), caption="Sunrise by the mountains")
